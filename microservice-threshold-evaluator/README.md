# üß† Hybrid Retrieval-Augmented LLM Plagiarism Detection

This module implements the most advanced approach to code plagiarism detection by combining vector similarity search with LLM-based analysis for highly accurate results.

## üß© How It Works

1. The system maintains a database of code from various repositories
2. Source code files are automatically extracted, normalized, and categorized by programming language
3. Normalized code is chunked, embedded using CodeBERT, and stored in a FAISS vector database
4. When new code is submitted for checking:
   - It's normalized, embedded, and compared against the vector database
   - The top most similar code chunks are retrieved
   - These chunks, along with the query code, are sent to an LLM (GPT-3.5/4)
   - The LLM performs a detailed plagiarism analysis considering code semantics and patterns
5. A comprehensive plagiarism report is generated with human-readable explanations

## üèóÔ∏è Architecture

The system consists of multiple integrated components:

- **Repository Management**: Clones GitHub repositories and extracts code files
- **Code Normalization**: Standardizes code by removing comments, whitespace variations, and case sensitivity
- **Vector Embedding**: Creates vector embeddings using CodeBERT for efficient similarity search
- **Vector Store**: FAISS-powered database for fast retrieval of similar code
- **LLM Analyzer**: Uses OpenAI's models to analyze potential plagiarism with human-like understanding
- **API Layer**: FastAPI endpoints for code submission and analysis

## üõ†Ô∏è Setup and Installation

### Prerequisites
- Python 3.8+
- OpenAI API key
- CUDA-compatible GPU (optional, for faster embedding generation)

### Installation
```bash
# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env file with your API keys and configuration
```

### Environment Variables
```
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.0

# Repository Sources
GITHUB_REPOSITORIES=https://github.com/repo1/example,https://github.com/repo2/example

# Embedding Configuration
EMBEDDING_MODEL=microsoft/codebert-base
MAX_TOKENS_PER_CHUNK=510
CHUNK_OVERLAP=100
```

## üöÄ Usage

### Starting the Service
```bash
uvicorn main:app --reload
```

### API Endpoints

#### 1. Plagiarism Check
```bash
curl -X POST http://localhost:8000/check-plagiarism \
  -H "Content-Type: application/json" \
  -d '{
    "code": "YOUR_CODE_HERE",
    "top_k": 5
  }'
```

#### 2. Managing Code Repository
```bash
# Clone and process repositories (extract, normalize, and embed - default behavior)
curl -X POST http://localhost:8000/clone-and-process

# Clone and process repositories without generating embeddings
curl -X POST http://localhost:8000/clone-and-process?embed=false

# Check status of repositories and vector store (shows file counts by language)
curl -X GET http://localhost:8000/status
```

### Response Format

#### Plagiarism Check Response
```json
{
  "plagiarism_detected": true,
  "analysis": "The submitted code appears to be plagiarized from repository X. While variable names have been changed, the overall structure, algorithm, and implementation logic are nearly identical to the original code. Specific matches include the function 'calculate_factorial' which has only superficial modifications.",
  "confidence": 0.92,
  "model_used": "gpt-3.5-turbo",
  "similar_chunks_count": 3
}
```

## ‚öôÔ∏è Implementation Details

### Code Normalization
- Removes comments (single-line, multi-line, and docstrings)
- Converts code to lowercase
- Normalizes whitespace and indentation
- Makes it harder to evade detection with superficial changes

### Vector Similarity
- Uses Microsoft's CodeBERT (768-dimensional vectors) for code-specific embeddings
- FAISS (Facebook AI Similarity Search) for efficient similarity search
- Retrieved similar code chunks serve as context for the LLM

### LLM Analysis
- Prompt engineering designed specifically for plagiarism detection
- LLM analyzes multiple code chunks together for more accurate assessment
- Returns structured analysis with confidence score
- Tenacity-based retry mechanism for API resilience

## ‚öñÔ∏è Advantages and Limitations

### Advantages
- Most accurate of all three approaches
- Understands code semantics, not just structural similarity
- Provides human-readable explanation of plagiarism findings
- Can detect sophisticated forms of plagiarism (renamed variables, reordered functions, etc.)
- Assigns confidence levels to plagiarism determinations
- Robust against simple code obfuscation techniques

### Limitations
- Most resource-intensive and costly of all three approaches
- Requires OpenAI API key and incurs usage costs
- Higher latency due to LLM API call
- Limited by the size of embedded repository (can only find what it knows)
- LLM context window restricts the number of code chunks that can be analyzed

## üìä Performance Expectations

- Typical response time: 1-3 seconds
- Accuracy on test plagiarism dataset: ~92%
- False positive rate: ~5%
- API cost: ~$0.001-0.02 per query (depending on OpenAI model used)

## üîÑ Next Steps

- Implement more sophisticated code normalization techniques
- Add support for multi-language plagiarism detection
- Create a fine-tuned model specifically for code plagiarism detection
- Implement caching to reduce API costs for repeated queries
- Develop a feedback mechanism to improve detection over time
- Add support for batch processing of multiple files